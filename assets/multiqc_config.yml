report_comment: >
  This report has been generated by the <a href="https://github.com/nf-core/variantbenchmarking/releases/tag/1.4.0" target="_blank">nf-core/variantbenchmarking</a> analysis pipeline. For information about how to interpret these results, please see the <a href="https://nf-co.re/variantbenchmarking/1.4.0/docs/output" target="_blank">documentation</a>.

report_section_order:
  "nf-core-variantbenchmarking-methods-description":
    order: -1000
  software_versions:
    order: -1001
  "nf-core-variantbenchmarking-summary":
    order: -1002

export_plots: true
disable_version_detection: true
ignore_images: false

# Customize General Statistics table
table_columns_visible:
  bcftools:
    number_of_MNPs: true
    number_of_others: true

# Run only these modules
run_modules:
  - bcftools
  - truvari
  - happy
  - sompy
  - custom_content

custom_data:
  survivor:
    id: "survivor"
    section_name: "SURVIVOR variant statistics"
    description: "generated by nf-core/survivor"
    plot_type: "bargraph"
    format: "tsv"
    pconfig:
      id: "survivor"
      namespace: "SURVIVOR variant statistics"
      table_title: "Variant statistics from survivor stats tool"
      ylab: "Count"

  summary_reports_1:
    id: "summary_reports_1"
    section_name: "Summary Benchmark Figures: Variants detected by tool"
    plot_type: "image"
    format: "png"

  summary_reports_2:
    id: "summary_reports_2"
    section_name: "Summary Benchmark Figures: Precision-Recall by tool"
    plot_type: "image"
    format: "png"

  summary_reports_3:
    id: "summary_reports_3"
    section_name: "Summary Benchmark Figures: F1 scores by tool"
    plot_type: "image"
    format: "png"

  summary_reports_4:
    id: "summary_reports_4"
    section_name: "Summary Benchmark Figures: FP INDEL lenght distrbutions"
    plot_type: "image"
    format: "png"

  summary_reports_5:
    id: "summary_reports_5"
    section_name: "Summary Benchmark Figures: FN INDEL lenght distrbutions"
    plot_type: "image"
    format: "png"

  summary_reports_6:
    id: "summary_reports_6"
    section_name: "Summary Benchmark Figures: TP comp INDEL lenght distrbutions"
    plot_type: "image"
    format: "png"

  summary_reports_7:
    id: "summary_reports_7"
    section_name: "Summary Benchmark Figures: TP base INDEL lenght distrbutions"
    plot_type: "image"
    format: "png"

  summary_reports_8:
    id: "summary_reports_8"
    section_name: "Summary Benchmark Figures: Upset plot for TP vs FN"
    plot_type: "image"
    format: "png"

  summary_reports_9:
    id: "summary_reports_9"
    section_name: "Summary Benchmark Figure: Upset plot for TP vs FP"
    plot_type: "image"
    format: "png"

  variant_calling_summary:
    file_format: "csv"
    section_name: "Variant Calling Summary"
    description: "Comparison of variant calling results across different tools"
    plot_type: "table"
    pconfig:
      id: "variant_calling_summary"
      title: "Variant Calling Performance Metrics"
      scale: false
      col1_header: "Tool"
    headers:
      File:
        title: "File"
        description: "Summary file name"
        scale: false
      Caller:
        title: "Caller"
        description: "Variant calling tool"
        scale: false
      TP_base:
        title: "TP (base)"
        description: "True positives in baseline"
        format: "{:,.0f}"
      TP_comp:
        title: "TP (comp)"
        description: "True positives in comparison"
        format: "{:,.0f}"
      FP:
        title: "FP"
        description: "False positives"
        format: "{:,.0f}"
      FN:
        title: "FN"
        description: "False negatives"
        format: "{:,.0f}"
      Precision:
        title: "Precision"
        description: "Precision metric"
        format: "{:,.4f}"
        max: 1.0
        min: 0.0
      Recall:
        title: "Recall"
        description: "Recall metric"
        format: "{:,.4f}"
        max: 1.0
        min: 0.0
      F1:
        title: "F1 Score"
        description: "F1 score metric"
        format: "{:,.4f}"
        max: 1.0
        min: 0.0

sp:
  survivor:
    fn: "*.stats"
  bcftools/stats:
    contents: This file was produced by bcftools stats
  truvari/bench:
    contents_re: .*truvari.* bench.*
    fn: "*log.txt"
    num_lines: 10
  happy:
    contents: Type,Filter,TRUTH
    fn: "*.summary.csv"
  sompy:
    contents: ",sompyversion,sompycmd"
    fn: "*.stats.csv"
    num_lines: 2
  summary_reports_1:
    fn: "variants_by_tool*.png"
  summary_reports_2:
    fn: "pr_recall_by_tool*.png"
  summary_reports_3:
    fn: "f1_by_tool*.png"
  summary_reports_4:
    fn: "*FP.structural*.png"
  summary_reports_5:
    fn: "*FN.structural*.png"
  summary_reports_6:
    fn: "*TP_comp.structural*.png"
  summary_reports_7:
    fn: "*TP_base.structural*.png"
  summary_reports_8:
    fn: "upset*tp_fn*.png"
  summary_reports_9:
    fn: "upset*tp_fp*.png"
  variant_calling_summary:
    fn: "*summary.csv"
    contents: "Tool,File,Caller"

module_order:
  - bcftools:
      name: "Input SNV/INDEL/DELETION statatistics"
  - survivor:
      name: "Input INDEL/DELETION statistics"
  - happy:
      name: "hap.py summary statistics"
  - sompy:
      name: "som.py summary statistics"
  - truvari/bench:
      name: "Truvari summary statistics"
  - variant_calling_summary
  - summary_reports_1
  - summary_reports_2
  - summary_reports_3
  - summary_reports_4
  - summary_reports_5
  - summary_reports_6
  - summary_reports_7
  - summary_reports_8
  - summary_reports_9
